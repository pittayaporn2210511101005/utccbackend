import pandas as pd
from sqlalchemy import create_engine
from openai import OpenAI

# ================================
# OLLAMA CLIENT
# ================================
client = OpenAI(
    base_url="http://localhost:11434/v1",
    api_key="ollama"
)

print("üß† Loading LLM ...")

# ================================
# HELPER: call LLM
# ================================
def ask_llm(prompt):
    try:
        res = client.chat.completions.create(
            model="llama3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        return res.choices[0].message.content.strip()
    except Exception as e:
        print("LLM ERROR:", e)
        return "neutral"


# ================================
# 1) Sentiment
# ================================
def detect_sentiment(text):
    prompt = f"""
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

    ‡∏Å‡∏é:
    - ‡∏ñ‡∏≤‡∏°‡πÄ‡∏â‡∏¢‡πÜ = neutral
    - ‡∏Ç‡∏≠‡∏£‡∏µ‡∏ß‡∏¥‡∏ß = neutral
    - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ = neutral
    - ‡∏ö‡πà‡∏ô ‡πÇ‡∏ß‡∏¢‡∏ß‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡∏û‡∏≠‡πÉ‡∏à = negative
    - ‡∏ä‡∏∑‡πà‡∏ô‡∏ä‡∏° = positive

    ‡∏ï‡∏≠‡∏ö:
    - positive
    - neutral
    - negative

    ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: "{text}"
    """
    return ask_llm(prompt)


# ================================
# 2) NSFW / Toxic / Hate
# ================================
def detect_nsfw_llm(text):
    prompt = f"""
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

    ‡∏Å‡∏é:
    - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°, ‡∏Ç‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Ç‡∏≠‡∏£‡∏µ‡∏ß‡∏¥‡∏ß ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏´‡∏¢‡∏≤‡∏ö = normal
    - ‡∏Ñ‡∏≥‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏û‡∏®‡∏´‡∏£‡∏∑‡∏≠ 18+ = sexual ‡∏´‡∏£‡∏∑‡∏≠ pornographic
    - ‡∏î‡πà‡∏≤/‡∏´‡∏¢‡∏≤‡∏ö‡∏Ñ‡∏≤‡∏¢/‡∏Å‡πâ‡∏≤‡∏ß‡∏£‡πâ‡∏≤‡∏ß = abusive ‡∏´‡∏£‡∏∑‡∏≠ toxic
    - ‡∏î‡∏π‡∏ñ‡∏π‡∏Å/‡πÄ‡∏´‡∏¢‡∏µ‡∏¢‡∏î/‡∏•‡πâ‡∏≠‡πÄ‡∏•‡∏µ‡∏¢‡∏ô = hate ‡∏´‡∏£‡∏∑‡∏≠ bully
    - ‡∏Ç‡∏π‡πà‡∏ó‡∏≥‡∏£‡πâ‡∏≤‡∏¢ = threatening

    ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏û‡∏µ‡∏¢‡∏á 1 label:
    sexual, pornographic, abusive, toxic, hate, bully,
    threatening, violent, normal

    ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: "{text}"
    """
    return ask_llm(prompt)


# ================================
# 3) Politeness
# ================================
def detect_politeness(text):
    prompt = f"""
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ:

    ‡∏Å‡∏é:
    - ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ, ‡∏Ç‡∏≠‡∏£‡∏µ‡∏ß‡∏¥‡∏ß, ‡∏´‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô, ‡∏ä‡∏ß‡∏ô‡∏Ñ‡∏∏‡∏¢ = neutral
    - ‡∏Ñ‡∏≥‡∏´‡∏¢‡∏≤‡∏ö ‡∏î‡πà‡∏≤ ‡∏õ‡∏£‡∏∞‡∏ä‡∏î‡πÅ‡∏£‡∏á = impolite
    - ‡∏°‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö/‡∏Ñ‡πà‡∏∞/‡∏ô‡∏∞‡∏Ñ‡∏∞/‡∏Ñ‡∏∞/‡∏Ñ‡∏£‡∏±‡∏ö = polite
    - ‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡πÉ‡∏î‡πÜ = neutral

    ‡∏ï‡∏≠‡∏ö:
    polite
    neutral
    impolite

    ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: "{text}"
    """
    return ask_llm(prompt)


# ================================
# 4) FINAL LABEL
# ================================
def final_classification(text):
    s = detect_sentiment(text)
    n = detect_nsfw_llm(text)
    p = detect_politeness(text)

    # 18+
    if n in ["sexual", "pornographic"]:
        return "‡∏•‡πà‡∏≠‡πÅ‡∏´‡∏•‡∏° / 18+"

    # toxic
    if n in ["abusive", "toxic", "hate", "bully", "threatening", "violent"]:
        return "‡∏î‡πà‡∏≤ / ‡∏Å‡πâ‡∏≤‡∏ß‡∏£‡πâ‡∏≤‡∏ß / ‡πÄ‡∏´‡∏¢‡∏µ‡∏¢‡∏î"

    # impolite
    if p == "impolite":
        return "‡∏´‡∏¢‡∏≤‡∏ö‡∏Ñ‡∏≤‡∏¢"

    # polite + positive
    if p == "polite" and s == "positive":
        return "‡∏™‡∏∏‡∏†‡∏≤‡∏û-‡∏ä‡∏°"

    if s == "positive":
        return "‡∏ä‡∏°"

    if s == "negative":
        return "‡∏ö‡πà‡∏ô / ‡∏ï‡∏≥‡∏´‡∏ô‡∏¥"

    return "‡∏õ‡∏Å‡∏ï‡∏¥"


# ================================
# DATABASE
# ================================
engine = create_engine(
    "mysql+pymysql://root:@localhost/backendutcc?charset=utf8mb4"
)

print("üì• Loading data from database ...")

df_tw = pd.read_sql("SELECT id, text, created_at FROM tweet", engine)
df_tw["platform"] = "twitter"

df_pt = pd.read_sql(
    "SELECT id, title AS text, post_time AS created_at FROM pantip_post", engine)
df_pt["platform"] = "pantip_post"

df_pc = pd.read_sql(
    "SELECT id, text, commented_at AS created_at FROM pantip_comment", engine)
df_pc["platform"] = "pantip_comment"

df = pd.concat([df_tw, df_pt, df_pc], ignore_index=True)
print(f"‚úÖ ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(df)} ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")

# ================================
# FACULTY DETECTION
# ================================
faculty_keywords = {
    "‡∏ö‡∏±‡∏ç‡∏ä‡∏µ": ["‡∏ö‡∏±‡∏ç‡∏ä‡∏µ","‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô"],
    "‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î": ["‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î"],
    "‡∏ô‡∏¥‡πÄ‡∏ó‡∏®‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå": ["‡∏ô‡∏¥‡πÄ‡∏ó‡∏®", "‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£", "event"],
    "‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß": ["‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß", "‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏Å‡∏≤‡∏£‡∏ö‡∏¥‡∏ô", "‡∏Å‡∏≤‡∏£‡∏ö‡∏¥‡∏ô"],
    "‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à": ["‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£", "‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£", "‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à","‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£"],
    "‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå": ["‡πÄ‡∏®‡∏£‡∏©‡∏ê"],
    "‡πÇ‡∏•‡∏à‡∏¥‡∏™‡∏ï‡∏¥‡∏Å‡∏™‡πå": ["‡πÇ‡∏•‡∏à‡∏¥‡∏™"],
    "‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå": ["‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå", "‡∏≠‡∏¥‡πâ‡∏á","‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå","‡πÄ‡∏Å‡∏≤‡∏´‡∏•‡∏µ","‡∏à‡∏µ‡∏ô","epic"],
    "‡∏ó‡∏∏‡∏ô‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢": ["‡∏ó‡∏∏‡∏ô"],
    "‡∏Å‡∏¢‡∏™": ["‡∏Å‡∏¢‡∏®", "‡∏Å‡∏π‡πâ"],
    "‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå": ["‡∏ß‡∏¥‡∏ó‡∏Ñ‡∏≠‡∏°", "‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ", "‡∏≠‡∏≤‡∏´‡∏≤‡∏£"],
    "‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£": ["‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠", "‡∏™‡∏≥‡∏ô‡∏±‡∏Å", "‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£", "‡∏£‡∏∞‡∏ö‡∏ö"],
}

def detect_faculty(text):
    t = text.lower()
    for f, keys in faculty_keywords.items():
        if any(k.lower() in t for k in keys):
            return f
    return "‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°"

df["faculty"] = df["text"].apply(detect_faculty)

# ================================
# RUN ANALYSIS (with progress)
# ================================
print("‚öôÔ∏è Running full AI analysis ...")

sentiments = []
nsfws = []
polites = []
finals = []

total = len(df)

for i, text in enumerate(df["text"], start=1):
    print(f"Analyzing {i}/{total}...")

    s = detect_sentiment(text)
    n = detect_nsfw_llm(text)
    p = detect_politeness(text)
    f = final_classification(text)

    sentiments.append(s)
    nsfws.append(n)
    polites.append(p)
    finals.append(f)

df["sentiment"] = sentiments
df["nsfw"] = nsfws
df["politeness"] = polites
df["final_label"] = finals


# ================================
# SAVE
# ================================
df.to_sql("social_analysis", con=engine, if_exists="replace", index=False)

print("üéâ DONE!")
print(f"üíæ Saved {len(df)} rows into social_analysis")