import pandas as pd
from sqlalchemy import create_engine
from openai import OpenAI
import requests

# ================================
# OLLAMA CLIENT
# ================================
client = OpenAI(
    base_url="http://localhost:11434/v1",
    api_key="ollama"
)

# ================================
# LOAD CUSTOM KEYWORDS FROM BACKEND
# ================================
def load_custom_keywords():
    url = "http://localhost:8082/custom-keywords/all"
    data = requests.get(url).json()
    return {item["keyword"]: item["sentiment"] for item in data}

def apply_custom_dict(text, ai_sentiment, custom_dict):
    for word, sent in custom_dict.items():
        if word in text:
            return sent  # Override sentiment by user-configured label
    return ai_sentiment

print("üß† Loading LLM ...")

# ================================
# HELPER: call LLM
# ================================
def ask_llm(prompt):
    try:
        res = client.chat.completions.create(
            model="llama3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        return res.choices[0].message.content.strip()
    except Exception as e:
        print("LLM ERROR:", e)
        return ""

# ================================
# Extract label from messy response
# ================================
def extract_label(text, choices, default):
    t = text.lower()
    for c in choices:
        if c.lower() in t:
            return c
    return default

# ================================
# 1) SENTIMENT
# ================================
def detect_sentiment(text):
    prompt = f"""
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
    ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡πÄ‡∏î‡∏µ‡∏¢‡∏ß: positive, neutral, negative
    ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: "{text}"
    """
    raw = ask_llm(prompt)
    return extract_label(raw, ["positive", "neutral", "negative"], "neutral")

# ================================
# 2) NSFW
# ================================
def detect_nsfw_llm(text):
    prompt = f"""
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ:

    ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏û‡∏µ‡∏¢‡∏á 1 ‡∏Ñ‡∏≥:
    sexual, pornographic, abusive, toxic, hate,
    bully, threatening, violent, normal

    ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: "{text}"
    """
    raw = ask_llm(prompt)
    return extract_label(
        raw,
        ["sexual", "pornographic", "abusive", "toxic", "hate",
         "bully", "threatening", "violent", "normal"],
        "normal"
    )

# ================================
# 3) POLITENESS
# ================================
def detect_politeness(text):
    prompt = f"""
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏†‡∏≤‡∏û:

    ‡∏ï‡∏≠‡∏ö:
    polite
    neutral
    impolite

    ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: "{text}"
    """
    raw = ask_llm(prompt)
    return extract_label(raw, ["polite", "neutral", "impolite"], "neutral")

# ================================
# 4) FINAL LABEL
# ================================
def final_classification(sentiment, nsfw, politeness):
    if nsfw in ["sexual", "pornographic"]:
        return "‡∏•‡πà‡∏≠‡πÅ‡∏´‡∏•‡∏° / 18+"

    if nsfw in ["abusive", "toxic", "hate", "bully", "threatening", "violent"]:
        return "‡∏î‡πà‡∏≤ / ‡∏Å‡πâ‡∏≤‡∏ß‡∏£‡πâ‡∏≤‡∏ß / ‡πÄ‡∏´‡∏¢‡∏µ‡∏¢‡∏î"

    if politeness == "impolite":
        return "‡∏´‡∏¢‡∏≤‡∏ö‡∏Ñ‡∏≤‡∏¢"

    if politeness == "polite" and sentiment == "positive":
        return "‡∏™‡∏∏‡∏†‡∏≤‡∏û-‡∏ä‡∏°"

    if sentiment == "positive":
        return "‡∏ä‡∏°"

    if sentiment == "negative":
        return "‡∏ö‡πà‡∏ô / ‡∏ï‡∏≥‡∏´‡∏ô‡∏¥"

    return "‡∏õ‡∏Å‡∏ï‡∏¥"

# ================================
# DATABASE
# ================================
engine = create_engine(
    "mysql+pymysql://root:@localhost/backendutcc?charset=utf8mb4"
)

print("üì• Loading data from database ...")

df_tw = pd.read_sql("SELECT id, text, created_at FROM tweet", engine)
df_tw["platform"] = "twitter"

df_pt = pd.read_sql(
    "SELECT id, title AS text, post_time AS created_at FROM pantip_post", engine)
df_pt["platform"] = "pantip_post"

df_pc = pd.read_sql(
    "SELECT id, text, commented_at AS created_at FROM pantip_comment", engine)
df_pc["platform"] = "pantip_comment"

df = pd.concat([df_tw, df_pt, df_pc], ignore_index=True)
print(f"‚úÖ ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(df)} ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")

# ================================
# FACULTY DETECTION
# ================================
faculty_keywords = {
    "‡∏ö‡∏±‡∏ç‡∏ä‡∏µ": ["‡∏ö‡∏±‡∏ç‡∏ä‡∏µ","‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô"],
    "‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î": ["‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î"],
    "‡∏ô‡∏¥‡πÄ‡∏ó‡∏®‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå": ["‡∏ô‡∏¥‡πÄ‡∏ó‡∏®", "‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£", "event"],
    "‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß": ["‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß", "‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏Å‡∏≤‡∏£‡∏ö‡∏¥‡∏ô", "‡∏Å‡∏≤‡∏£‡∏ö‡∏¥‡∏ô"],
    "‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à": ["‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£", "‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£", "‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à","‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£"],
    "‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå": ["‡πÄ‡∏®‡∏£‡∏©‡∏ê"],
    "‡πÇ‡∏•‡∏à‡∏¥‡∏™‡∏ï‡∏¥‡∏Å‡∏™‡πå": ["‡πÇ‡∏•‡∏à‡∏¥‡∏™"],
    "‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå": ["‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå", "‡∏≠‡∏¥‡πâ‡∏á","‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå","‡πÄ‡∏Å‡∏≤‡∏´‡∏•‡∏µ","‡∏à‡∏µ‡∏ô","epic"],
    "‡∏ó‡∏∏‡∏ô‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢": ["‡∏ó‡∏∏‡∏ô"],
    "‡∏Å‡∏¢‡∏™": ["‡∏Å‡∏¢‡∏®", "‡∏Å‡∏π‡πâ"],
    "‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå": ["‡∏ß‡∏¥‡∏ó‡∏Ñ‡∏≠‡∏°", "‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ", "‡∏≠‡∏≤‡∏´‡∏≤‡∏£"],
    "‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£": ["‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠", "‡∏™‡∏≥‡∏ô‡∏±‡∏Å", "‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£", "‡∏£‡∏∞‡∏ö‡∏ö"],
}

def detect_faculty(text):
    t = text.lower()
    for f, keys in faculty_keywords.items():
        if any(k.lower() in t for k in keys):
            return f
    return "‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°"

df["faculty"] = df["text"].apply(detect_faculty)

# ================================
# LOAD custom_dict HERE (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å!!)
# ================================
custom_dict = load_custom_keywords()
print("üìå Loaded custom keywords:", custom_dict)

# ================================
# RUN ANALYSIS
# ================================
print("‚öôÔ∏è Running AI analysis ...")

sentiments = []
nsfws = []
polites = []
finals = []

total = len(df)

for i, text in enumerate(df["text"], start=1):
    print(f"Analyzing {i}/{total}...")

    # AI sentiment
    ai_sent = detect_sentiment(text)

    # Override sentiment by custom keywords
    final_sent = apply_custom_dict(text, ai_sent, custom_dict)

    n = detect_nsfw_llm(text)
    p = detect_politeness(text)
    f = final_classification(final_sent, n, p)

    sentiments.append(final_sent)
    nsfws.append(n)
    polites.append(p)
    finals.append(f)

df["sentiment"] = sentiments
df["nsfw"] = nsfws
df["politeness"] = polites
df["final_label"] = finals

# ================================
# SAVE TO DB
# ================================
df.to_sql("social_analysis", con=engine, if_exists="replace", index=False)

print("üéâ DONE!")
print(f"üíæ Saved {len(df)} rows into social_analysis")
